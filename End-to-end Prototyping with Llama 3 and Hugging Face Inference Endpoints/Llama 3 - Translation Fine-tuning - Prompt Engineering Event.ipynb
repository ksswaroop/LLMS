{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d9ce926-7309-40c1-8c1c-4f3f8f5e0e75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (4.44.2)\n",
      "Collecting peft\n",
      "  Using cached peft-0.12.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting trl\n",
      "  Using cached trl-0.10.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: accelerate in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (0.34.2)\n",
      "Requirement already satisfied: bitsandbytes in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (0.43.3)\n",
      "Requirement already satisfied: datasets in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (2.21.0)\n",
      "Requirement already satisfied: filelock in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from transformers) (0.24.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: psutil in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from peft) (5.9.0)\n",
      "Requirement already satisfied: torch>=1.13.0 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from peft) (2.2.2)\n",
      "Collecting tyro>=0.5.11 (from trl)\n",
      "  Using cached tyro-0.8.10-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from datasets) (2.2.1)\n",
      "Requirement already satisfied: xxhash in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from datasets) (3.10.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.7)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from requests->transformers) (2024.7.4)\n",
      "Requirement already satisfied: sympy in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from torch>=1.13.0->peft) (1.13.2)\n",
      "Requirement already satisfied: networkx in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from torch>=1.13.0->peft) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from torch>=1.13.0->peft) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from torch>=1.13.0->peft) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from torch>=1.13.0->peft) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from torch>=1.13.0->peft) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from torch>=1.13.0->peft) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.6.68)\n",
      "Collecting docstring-parser>=0.16 (from tyro>=0.5.11->trl)\n",
      "  Using cached docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: rich>=11.1.0 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from tyro>=0.5.11->trl) (13.8.0)\n",
      "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl)\n",
      "  Using cached shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.15.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/swaroop/miniconda3/envs/torch/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n",
      "Using cached peft-0.12.0-py3-none-any.whl (296 kB)\n",
      "Using cached trl-0.10.1-py3-none-any.whl (280 kB)\n",
      "Using cached tyro-0.8.10-py3-none-any.whl (105 kB)\n",
      "Using cached docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Using cached shtab-1.7.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: shtab, docstring-parser, tyro, trl, peft\n",
      "Successfully installed docstring-parser-0.16 peft-0.12.0 shtab-1.7.1 trl-0.10.1 tyro-0.8.10\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers peft trl accelerate bitsandbytes datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4875509c-558c-4971-8339-1245d90f9d12",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "We'll be using a dataset that is adept at translating English to Gen-Z Slang laden English for this version of the model.\n",
    "\n",
    "This dataset contains the following:\n",
    "\n",
    "    English\n",
    "    Gen-Z Language (still English)\n",
    "\n",
    "We'll start by grabbing our dataset from Hugging Face!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ddc7d50-b31c-4d9c-9220-ea1e858b1833",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "gen_z_dataset = load_dataset(\"ai-maker-space/gen-z-translation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c55c3f23-5a3d-4d5f-b6b1-d19ecc349427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['English', 'Gen-Z'],\n",
       "        num_rows: 105\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_z_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34ef39a5-2335-4ec3-bd67-eb1c29a499cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: She's very good at manipulating people to get what she wants. \n",
      "\n",
      "Gen-z: She's got mad finesse, always getting her way.\n"
     ]
    }
   ],
   "source": [
    "print(f\"English: {gen_z_dataset['train'][70]['English']} \\n\\nGen-z: {gen_z_dataset['train'][70]['Gen-Z']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa9210d-be91-41bf-9551-1199f3c1c401",
   "metadata": {},
   "source": [
    "### LLAMA3 Template\n",
    "Let's look at an example of how we might format our instruction - and then reproduce that in code."
   ]
  },
  {
   "cell_type": "raw",
   "id": "1ad664f0-f258-4a8b-a04f-2377aa34f5c4",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "Gen-Z-ify<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "She's very good at manipulating people to get what she wants.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "She's got mad finesse, always getting her way.<|eot_id|>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75a040bf-2787-42e2-9883-79995f232a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTRUCTION_PROMPT_TEMPLATE = \"\"\"\\\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "Gen-Z-ify<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{english}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\"\n",
    "\n",
    "RESPONSE_TEMPLATE = \"\"\"\\\n",
    "{gen_z_slang}<|eot_id|><|end_of_text|>\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41840d3-cc52-499a-bad4-6841fb0594ef",
   "metadata": {},
   "source": [
    "Now we can create a helper function that will convert our dataset row into the above prompt!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15b08670-08dc-4f11-8378-939ecc77ae3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_instruction(sample, return_response=True):\n",
    "  prompt = INSTRUCTION_PROMPT_TEMPLATE.format(\n",
    "      english=sample[\"English\"]\n",
    "  )\n",
    "\n",
    "  if return_response:\n",
    "    prompt += RESPONSE_TEMPLATE.format(gen_z_slang=sample[\"Gen-Z\"])\n",
    "\n",
    "  return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7987f3d-12d7-44f1-b8e3-7c8894673b66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nGen-Z-ify<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nThat was really funny.<|eot_id|><|start_header_id|>assistant<|end_header_id|>I'm weak.<|eot_id|><|end_of_text|>\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_instruction(gen_z_dataset['train'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011de928-82b9-4a9c-be89-5e89dad85745",
   "metadata": {},
   "source": [
    "### Loading Our Model\n",
    "We're going to be dependent on two major technologies to allow us to train our model with <=16GB GPU RAM.\n",
    "\n",
    "    Quantization\n",
    "    LoRA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d8c2bd0-da4a-4f68-b939-26172501bae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5afdcd749a24aff95dbd3c57167a6ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c50ec8d9-8fbe-4d4e-b18d-a3496085feab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "655729224dfc418b9b0ec0b6867f115e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    quantization_config=quantization_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f752439a-beeb-40e8-8c75-39cfd210e353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d8a5a91-8cd0-4561-9840-7785727a491a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83c9bec8-cd64-46a7-879b-7e21f83eda62",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a43c5052-e6e5-4bb3-ae08-2a115f503610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'They are in a very complicated romantic relationship.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_z_dataset[\"train\"][75][\"English\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "374e7c81-124a-4754-9e7b-71043e96bf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "base_model_pipe = pipeline(\"text-generation\",model,tokenizer=tokenizer,max_new_tokens=256,return_full_text=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1054ec44-efd1-48a9-bbd9-6bd0989c93e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'She looks very attractive.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_z_dataset[\"train\"][2][\"English\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f055c98-514b-40c3-833d-e2f5b9a29308",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = base_model_pipe(create_instruction(gen_z_dataset[\"train\"][2], return_response=False), do_sample=True, max_new_tokens=256, temperature=0.1, top_k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e090700a-7b61-4811-8669-9cdca1ec5324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"\\n\\nYou're saying she's low-key goals, right? Like, she's got that effortless cool thing going on, and you can't help but be drawn to her. Am I right?\"}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209494dc-e276-4f01-9194-dece6a0d6027",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (torch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
